# Transformer-based Long Document Modeling

This repo aims at providing a collection of Transformer-based Model for Long Document Modeling. 

## Hierarchical Models

| Year | Venue | Title                                                                                                                                     | Paper                                                       |                                                                                Code                                                                                 |
|:-----|:------|:------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------:|
| 2019 | ACL   | HIBERT: Document Level Pre-training of Hierarchical Bidirectional Transformers for Document Summarization                                   | [link](https://arxiv.org/abs/1905.06566)                    |                                                         [code](https://xingxingzhang.github.io/hibert.html)                                                         |
| 2019 | ASRU  | Hierarchical Transformers for Long Document Classification                                                                    | [link](https://ieeexplore.ieee.org/abstract/document/9003958)                    |                                        [code](https://paperswithcode.com/paper/hierarchical-transformers-for-long-document)                                         |
| 2020 | EMNLP | Unsupervised Extractive Summarization by Pre-training Hierarchical Transformers                                                            | [link](https://arxiv.org/abs/2010.08242)                    |                                                              [code](https://github.com/xssstory/STAS)                                                               |
| 2020 | CIKM  | Beyond 512 Tokens: Siamese Multi-depth Transformer-based Hierarchical Encoder for Long-Form Document Matching                                  | [link](https://dl.acm.org/doi/abs/10.1145/3340531.3411908)                    |                                            [code](https://github.com/google-research/google-research/tree/master/smith)                                             |
| 2021 | ICDMW | Transformer-based Hierarchical Encoder for Document Classification                                                                        | [link](https://ieeexplore.ieee.org/abstract/document/9679873)          |                                                                                                                                                                     |
| 2021 | ACL   | Hi-Transformer: Hierarchical Interactive Transformer for Efficient and Effective Long Document Modeling                                                                                              | [link](https://arxiv.org/abs/2106.01040)                    |                                                                                                                                                                     |
| 2022 | ACL   | Efficient Classification of Long Documents Using Transformers                                                                           | [link](https://arxiv.org/abs/2203.11258)                    |                                             [code](https://github.com/amazon-science/efficient-longdoc-classification)                                              |
| 2022 | ACL   | KinyaBERT: a Morphology-aware Kinyarwanda Language Model                                                                     | [link](https://arxiv.org/abs/2203.08459)                    |                                                       [code](https://github.com/anzeyimana/kinyabert-acl2022)                                                       |
| 2022 | EMNLP | Revisiting Transformer-based Models for Long Document Classification                                                                                                      | [link](https://arxiv.org/abs/2204.06683)                    |                                                             [code](https://github.com/coastalcph/trldc)                                                             |
| 2022 | ACL   | HiStruct+: Improving Extractive Text Summarization with Hierarchical Structure Information                                                          | [link](https://arxiv.org/abs/2203.09629)                    |                                                            [code](https://github.com/QianRuan/histruct)                                                             |
| 2023 |       | A Survey on Long Text Modeling with Transformers                                                                                     | [link](https://arxiv.org/abs/2302.14502)                    |                                                                                                                                                                     |
| 2024 | ACL   | NextLevelBERT: Masked Language Modeling with Higher-Level Representations for Long Documents                                              | [link](https://arxiv.org/abs/2402.17682)                    |                                                   [code](https://github.com/aiintelligentsystems/next-level-bert)                                                   |

## Acknowledgement

Thanks for https://github.com/okhat/blog/blob/main/2024.09.impact.md.
Thanks for https://github.com/fla-org/flash-linear-attention.
